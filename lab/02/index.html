<!DOCTYPE HTML>
<html lang="zh-Hans" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>实验 2：使用 FMM、BMM 算法分词 - Learn NLP</title>
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../../favicon.svg">
        <link rel="shortcut icon" href="../../favicon.png">
        <link rel="stylesheet" href="../../css/variables.css">
        <link rel="stylesheet" href="../../css/general.css">
        <link rel="stylesheet" href="../../css/chrome.css">
        <link rel="stylesheet" href="../../css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="../../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../../fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../highlight.css">
        <link rel="stylesheet" href="../../tomorrow-night.css">
        <link rel="stylesheet" href="../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../../theme/css/custom-style.css">
        <link rel="stylesheet" href="../../theme/css/custom-font.css">
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../../index.html">首页</a></li><li class="chapter-item expanded "><a href="../../lab/index.html"><strong aria-hidden="true">1.</strong> 实验</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../../lab/01/index.html"><strong aria-hidden="true">1.1.</strong> 实验 1：互联网语料获取</a></li><li class="chapter-item expanded "><a href="../../lab/02/index.html" class="active"><strong aria-hidden="true">1.2.</strong> 实验 2：使用 FMM、BMM 算法分词</a></li><li class="chapter-item expanded "><a href="../../lab/misc/report-template.html"><strong aria-hidden="true">1.3.</strong> 实验报告模板</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Learn NLP</h1>

                    <div class="right-buttons">
                        <a href="../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/tsagaanbar/learn-NLP" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        <a href="https://github.com/tsagaanbar/learn-NLP/edit/main/src/lab/02/README.md" title="Suggest an edit" aria-label="Suggest an edit">
                            <i id="git-edit-button" class="fa fa-edit"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="自然语言处理实验二"><a class="header" href="#自然语言处理实验二">自然语言处理：实验二</a></h1>
<!-- {{#include ../misc/authors.html}} -->
<table>
    <style>
        th { text-justify: distribute; text-align-last: justify; text-align: justify; text-align: center; }
        td { text-align: center; }
    </style>
    <tbody>
        <tr><th>学院</th><td>信息工程学院</td></tr>
        <tr><th>指导教师</th><td>孙媛</td></tr>
        <tr><th>班级</th><td>19 级计算机科学与技术 1 班</td></tr>
        <tr><th>学生姓名</th><td>John Doe</td></tr>
        <tr><th>学号</th><td>19000000</td></tr>
    </tbody>
</table>
<p>日期： 2021 年 10 月 21 日</p>
<h2 id="摘要"><a class="header" href="#摘要">摘要</a></h2>
<h2 id="目录"><a class="header" href="#目录">目录</a></h2>
<h2 id="一实验内容"><a class="header" href="#一实验内容">一、实验内容</a></h2>
<p>实验内容：</p>
<ul>
<li>对语料库的文本进行分词并存储。</li>
<li>分别采用正向最大匹配算法、逆向最大匹配算法进行分词。以 <a href="https://github.com/fxsjy/jieba">jieba</a> 分词的分词结果作为标准语料，计算P、R、F值。</li>
</ul>
<h2 id="二实验原理"><a class="header" href="#二实验原理">二、实验原理</a></h2>
<h3 id="基于词典的切分方法"><a class="header" href="#基于词典的切分方法">基于词典的切分方法</a></h3>
<p>句子 \(S = c_1 c_2 \cdots c_n\)：句子由若干字符 \(c\) 组成。</p>
<p>假设词 \(w_i = c_1 c_2 \cdots c_m\)，其中 \(m\) 为词典中最长词的字数。</p>
<p>当前的分词算法主要分为两类——基于词典的规则匹配方法和基于统计的机器学习方法。</p>
<p>基于词典的分词算法，本质上就是字符串匹配。将待匹配的字符串基于一定的算法策略，和一个足够大的词典进行字符串匹配，如果匹配命中，则可以分词。根据不同的匹配策略，又分为正向最大匹配法，逆向最大匹配法，双向匹配分词，全切分路径选择等。</p>
<p>最大匹配法（Maximum Matching, MM）主要分为三种：</p>
<ul>
<li>正向最大匹配算法（Forward MM, FMM）：从左到右对语句进行匹配，匹配的词越长越好。这种方式切分会有歧义问题出现。</li>
<li>逆向最大匹配算法（Backward MM, BMM）：从右到左对语句进行匹配，同样也是匹配的词越长越好。这种方式同样也会有歧义问题。</li>
<li>双向最大匹配算法（Bi-directional MM）：则同时采用正向最大匹配和逆向最大匹配，选择二者分词结果中词数较少者。但这种方式同样会产生歧义问题。由此可见，词数少也不一定划分就正确。</li>
</ul>
<p><strong>全切分路径选择</strong>，将所有可能的切分结果全部列出来，从中选择最佳的切分路径。分为两种选择方法：</p>
<ol>
<li>n 最短路径方法。将所有的切分结果组成有向无环图，切词结果作为节点，词和词之间的边赋予权重，找到权重和最小的路径即为最终结果。比如可以通过词频作为权重，找到一条总词频最大的路径即可认为是最佳路径。</li>
<li>n 元语法模型。同样采用 n 最短路径，只不过路径构成时会考虑词的上下文关系。一元表示考虑词的前后一个词，二元则表示考虑词的前后两个词。然后根据语料库的统计结果，找到概率最大的路径。</li>
</ol>
<p>此次实验默认使用的是实验指导书中提供的词典。</p>
<h3 id="jieba-分词库"><a class="header" href="#jieba-分词库">jieba 分词库</a></h3>
<p><a href="https://github.com/fxsjy/jieba">jieba</a> 支持三种分词模式:</p>
<ol>
<li>精确分词，试图将句子最精确的切开，适合文本分析</li>
<li>全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义</li>
<li>搜索引擎模式，在精确模式基础上，对长词进行再次切分，提高recall，适合于搜索引擎。</li>
</ol>
<h3 id="扩充词典"><a class="header" href="#扩充词典">扩充词典</a></h3>
<p>将过程中遇到的“新词”添加进词典，可以提高文本识别的准确率。</p>
<h3 id="准确率召回率及-f-值"><a class="header" href="#准确率召回率及-f-值">准确率、召回率及 F 值</a></h3>
<p>机器学习中的分类评估包含有以下这么几个概念。</p>
<p>准确率（Accuracy），即正确分类的数量占总的数量的比值，是一个用来衡量分类器预测结果与真实结果差异的一个指标，越接近于 1 说明分类结果越准确。</p>
<p>二分类的结果有以下几种可能性：</p>
<ul>
<li>True Positive（TP）：表示将正样本预测为正样本，即预测正确；</li>
<li>False Positive（FP）：表示将负样本预测为正样本，即预测错误；</li>
<li>False Negative（FN）：表示将正样本预测为负样本，即预测错误；</li>
<li>True Negative（TN）：表示将负样本预测为负样本，即预测正确；</li>
</ul>
<p>精确率（Precision）计算的是预测对的正样本在整个预测为正样本中的比重，而召回率（Recall）计算的是预测对的正样本在整个真实正样本中的比重。因此，一般来说，召回率越高，意味着模型找寻正样本的能力越强。但值得注意的是，在实际任务中，并不明确哪一类是正样本或哪一类是负样本，所以对于每个类别，都可以计算其各项指标。</p>
<p>\[
\begin{align}
\text{Accuracy} = &amp; \frac{TP+TN}{TP+FP+FN+TN} \\
\text{Precision} = &amp; \frac{TP}{TP+FP} \\
\text{Recall} = &amp; \frac{TP}{TP+FN} \\
\end{align}
\]</p>
<p>实际评估一个系统时，应同时考虑 P 和 R，但同时要比较两个数值，很难做到一目了然。所以常采用综合两个值进行评价的办法，综合指标 F 值就是其中一种。计算公式如下：</p>
<p>\[
\text{F-score} = (1+\beta^2)\frac{P \times R}{\beta^2 \times P + R}
\]</p>
<p>其中，\(\beta\) 决定对 P 侧重还是对 R 侧重，通常设定为 1、2 或 \(\frac 1 2\)。\(\beta\) 取值为 1，即对二者一样重视，这时的 F-score 称为 \(F_1\) 值。</p>
<h3 id="分词结果的评估"><a class="header" href="#分词结果的评估">分词结果的评估</a></h3>
<p>机器学习中二分类的评估标准，无法直接应用于分词。</p>
<p>在对汉语分词性能进行评估时，采用了常用的３个评测指标：准确率（P）、召回率（R）、综合指标 F 值（F）。准确率表示在切分的全部词语中，正确的所占的比值。召回率指在所有切分词语中（包括切分的和不应该忽略的），正确切分的词语所占的比值。准确率描述系统切分的词语中，正确的占多少。召回率表示应该得到的词语中，系统正确切分出了多少。计算公式如下：</p>
<p>\[
P = \frac{\text{准确切分的词语数}}{\text{切分出的所有词语数}}
\]</p>
<p>\[
R = \frac{\text{准确切分的词语数}}{\text{应该切分的词语数}}
\]</p>
<p>若一字符串的分词结果为一系列单词，设每个单词按照其在文中的起止位置可记作区间 \([i,j]\)（\(0\leq i \leq j \leq n\)），那么标准答案对应的所有区间就可以构成一集合 \(A\)，作为正类，其他的区间则作为负类;同理，根据分词结果，可以得到集合 \(B\)。</p>
<p>\[TP \cup FN = A \]</p>
<p>\[TP \cup FP = B \]</p>
<p>\[A \cap B = TP \]</p>
<p>则 P、R 的计算公式：\(\text{Precision} = \frac{\vert A\cap B\vert}{\vert B \vert}\)，
\(\text{Recall} = \frac{\vert A\cap B\vert}{\vert A \vert}\)</p>
<h2 id="三整体框架"><a class="header" href="#三整体框架">三、整体框架</a></h2>
<p>主要分为功能模块和使用调用。详见主要程序模块。</p>
<h2 id="四主要程序模块"><a class="header" href="#四主要程序模块">四、主要程序模块</a></h2>
<h3 id="功能模块设计"><a class="header" href="#功能模块设计">功能模块设计</a></h3>
<p>考虑到可能会涉及大量词语的存储与检索，尝试使用将词库载入并存储于自己实现的 Trie 字典树结构中。</p>
<p>为了简便起见，使用 Python 中的字典结构模拟节点对象。</p>
<p><a href="./my_trie.py">my_trie.py</a></p>
<pre><code class="language-python">def insert(node, s):
    current = node
    for c in s:
        if c not in current['children'].keys():
            current['children'][c] = { 'c': c, 'children':dict(), 'cnt': 0 }
        current = current['children'][c]
    current['cnt'] += 1


def find(node, s):
    for c in s:
        if c in node['children'].keys():
            node = node['children'][c]
        else:
            return False
    return node['cnt'] &gt; 0


def traverse(node, s=''):
    for key in node['children'].keys():
        s += node['children'][key]['c']
        yield from traverse(node['children'][key], s)
        s = s[:-1]
    if node['cnt'] &gt; 0:
        yield s

</code></pre>
<p>使用示例：</p>
<p><a href="./trie_test.py">trie_test.py</a></p>
<pre><code class="language-python">import my_trie as trie

root = { 'c': '', 'children':dict(), 'cnt': 0 }

trie.insert(root, 'apple')
trie.insert(root, 'loop')
trie.insert(root, 'app')

test_cases = [
    ('a', False),
    ('ap', False),
    ('app', True),
    ('appl', False),
    ('apple', True),
    ('l', False),
    ('lo', False),
    ('loo', False),
    ('loop', True),
    ('loopa', False),
    ('loopan', False)
]

for t in test_cases:
    print(t[0], '\tExpected: ', t[1], '\tGot: ', trie.find(root, t[0]))

print('All words:')

for w in trie.traverse(root):
    print(w)
</code></pre>
<p>从文件中加载字典到 Trie 树，以及进行最大正向匹配（FMM）、最大逆向匹配（BMM）的功能：</p>
<p><a href="./FMM_BMM_trie.py">FMM_BMM_trie.py</a> </p>
<pre><code class="language-python">from my_trie import *

def load_wordlist(filename):
    wordlist = { 'c': '', 'children':dict(), 'cnt': 0 }
    maxlen = 0
    cnt = 0
    with open(filename) as f:
        if f.readline().strip() == '@Lexicon':
            for line in f:
                word = line.split()[1]
                maxlen = max(maxlen, len(word))
                insert(wordlist, word)
                cnt += 1
    return wordlist, cnt, maxlen


def add_words(wordlist, cnt, maxlen, new_words):
    for w in new_words:
        if w.startswith(&quot;-&quot;) or w.startswith(&quot;.&quot;):
            # 排除可能的特殊符号串，如“----------”
            continue
        elif w.isdigit():
            # 同理，排除掉特殊情况，使得字典更具有普遍性
            continue
        cnt += 1
        maxlen = max(len(w), maxlen)
        insert(wordlist, w)
    return wordlist, cnt, maxlen


def save_wordlist(filename, wordlist):
    with open(filename, &quot;w&quot;, encoding='utf-8') as out:
        cnt = 0
        for w in traverse(wordlist):
            cnt += 1
            out.write(str(cnt) + ' ' + w + '\n')


def FMM(sentence, wordlist, maxlen):
    maxlen = max(1, maxlen)
    tokens = []
    i = 0
    while i &lt; len(sentence):
        n = len(sentence) - i # 未被切分的字串长度
        m = min(maxlen, n)
        w = sentence[i:i+m]
        while len(w) &gt; 1:
            if find(wordlist, w):
                break
            else:
                w = w[0:-1]
        tokens.append(w)
        i += len(w)
    return tokens


def BMM(sentence, wordlist, maxlen):
    maxlen = max(1, maxlen)
    tokens = []
    i = len(sentence)
    while i &gt;= 1:
        n = i # 未被切分的字串长度
        m = min(maxlen, n)
        w = sentence[i-m:i]
        while len(w) &gt; 1:
            if find(wordlist, w):
                break
            else:
                w = w[1:]
        tokens.append(w)
        i -= len(w)
    tokens.reverse()
    return tokens
</code></pre>
<blockquote>
<p>另有使用 Python 内建的 set 类型的版本：<a href="./FMM_BMM.py">FMM_BMM.py</a>。</p>
</blockquote>
<p>评估分词结果，以及计算 P、R、F 值：</p>
<p><a href="./calc.py">calc.py</a></p>
<pre><code class="language-python">special_characters = set(list(
    &quot;()[]+-*/&lt;&gt;|\\;:\&quot;\'\,.?!@#$%^&amp;~`\{\}（）【】《》，。？“”‘’；：——「」『』〔〕&quot;
))

#包括部分特殊字符，在进行分词比对时将特殊字符排除，以免对结果产生一定的影响

def calc_hits(truth, result):
    # 传入分词得到的结果（列表），以及“正确分词”结果
    cut_truth = [item for item in truth if item not in special_characters]
    cut_result = [item for item in result if item not in special_characters]
    i = 0       # 指向 truth 中的 token
    j = 0       # 指向 result 中的 token
    l1 = 0      # i 所指向词串，对应在原句中的长度
    l2 = 0      # j 所指向词串，对应在原句中的长度
    hits = 0
    missmatches = set()
    while i &lt; len(cut_truth) and j &lt; len(cut_result):
        if l1 &lt; l2:
            l1 += len(cut_truth[i])
            i += 1
        elif l1 &gt; l2:
            l2 += len(cut_result[j])
            j += 1
        else: 
            if cut_truth[i] == cut_result[j]:
                hits += 1
            else:
                # 记录未匹配到的“新词”
                missmatches.add(cut_truth[i])
            l1 += len(cut_truth[i])
            i += 1
            l2 += len(cut_result[j])
            j += 1
    
    return hits, len(truth), len(result), missmatches


def calc_PRF(hits, truth_len, result_len):
    P = hits / result_len       # precision
    R = hits / truth_len        # recall
    F = (2 * P * R) / (P + R)   # F_1
    return P, R, F
</code></pre>
<p>多文件处理：</p>
<p><a href="./file_processing.py">file_processing.py</a></p>
<pre><code class="language-python"># -*-coding:UTF-8 -*-
import os

def cut_txt(file_name, cut_methods_list):
    &quot;&quot;&quot;
    单个TXT文档处理，可以接收多个方法，
    :param file_name:   要处理的文件名
    :param cut_methods_list: 类似如下的列表 [(&quot;name&quot;, method), ...]
    :return: 存储分词结果的字典，以方法名作为键名
    &quot;&quot;&quot;
    results = dict()
    with open(file_name, &quot;r&quot;, encoding='utf-8') as f:
        for line in f:
            for pair in cut_methods_list:
                foo_name = pair[0]
                foo = pair[1]
                results[foo_name] = foo(line)
    return results


def write_results(file_name, results, delimiter='/', output_dir_prefix=''):
    &quot;&quot;&quot;
    将分词结果写出到文件
    &quot;&quot;&quot;
    for foo_name in results.keys():
        out_file_name = os.path.join(
            output_dir_prefix, 
            file_name + &quot;.&quot; + foo_name + &quot;.segmented&quot;)
        with open(out_file_name, 'w', encoding='utf-8') as out:
            out.write(
                delimiter.join(results[foo_name]))


def process_path(path, cut_methods_list):
    &quot;&quot;&quot;
    对目录下的所有文件进行处理
    :param path: 目录名
    :param cut_methods_list: 要采用的分词方法的列表
    :return: 文件名及对应结果的生成器
    &quot;&quot;&quot;
    ignore = ['href', '简介', 'segmented']
    for root, subdirs, files in os.walk(path):
        for f in files:
            file_name = os.path.join(root, f)

            # 如果文件名含有某些特征，跳过
            should_pass = False
            for kw in ignore:
                if file_name.find(kw) != -1:
                    should_pass = True
                    break
            if should_pass: continue

            # 当前正在处理的文件
            print(file_name)
            
            # 获得各方法的分词结果：results
            yield file_name, cut_txt(file_name, cut_methods_list)

</code></pre>
<h3 id="应用程序"><a class="header" href="#应用程序">应用程序</a></h3>
<p>交互式分词程序：</p>
<p><a href="./demo.py">demo.py</a></p>
<pre><code class="language-python">from FMM_BMM_trie import *
from calc import *

import jieba

wordlist, cnt, maxlen = load_wordlist('wordlist.dic')

while True:
    s = input().strip()
    if s == '#':
        break
    ground_truth = jieba.lcut(s)  # 'ground truth'
    fmm = FMM(s, wordlist, maxlen)
    bmm = BMM(s, wordlist, maxlen)

    print('jieba:     ', &quot;/&quot;.join(ground_truth))

    print('-' * 20)

    print('FMM:       ', &quot;/&quot;.join(fmm))
    hits, len_truth, len_result, _ = calc_hits(ground_truth, fmm)
    P, R, F = calc_PRF(hits, len_truth, len_result)
    print('Hits:      ', hits)
    print('Precision: ', P)
    print('Recall:    ', R)
    print('F:         ', F)

    print('-' * 20)

    print('BMM:       ', &quot;/&quot;.join(bmm))
    hits, len_truth, len_result, _ = calc_hits(ground_truth, bmm)
    P, R, F = calc_PRF(hits, len_truth, len_result)
    print('Hits:      ', hits)
    print('Precision: ', P)
    print('Recall:    ', R)
    print('F:         ', F)
</code></pre>
<p>打印统计信息帮助函数：</p>
<p><a href="./print_helper.py">print_helper.py</a></p>
<pre><code class="language-python">from calc import calc_PRF

def print_stat(foo_name, total_truth_cnt, total_result_cnt, total_hits):

    print('{} 分词结果：'.format(foo_name))
    print(&quot;{:&lt;8} 分词总共的数目：{}&quot;.format(foo_name, total_truth_cnt))
    print(&quot;{:&lt;8} 分词总共的数目：{}&quot;.format(foo_name, total_result_cnt))
    print(&quot;{:&lt;8} 分词正确的数目：{}&quot;.format(foo_name, total_hits))

    P, R, F = calc_PRF(total_hits, total_truth_cnt, total_result_cnt)

    print(&quot;准确率（P）：{:.5f} %&quot;.format(100 * P))
    print(&quot;回归率（R）：{:.5f} %&quot;.format(100 * R))
    print(&quot;F 值为：{}&quot;.format(F))
</code></pre>
<p>对文档进行分词尝试，对最大匹配算法进行评估，并记录新词：</p>
<p><a href="./train.py">train.py</a></p>
<pre><code class="language-python">import jieba
from FMM_BMM_trie import *   # 根据路径不同修改
from calc import *
from file_processing import * 

trainning_file_path = [
    &quot;成都理工大学&quot;, 
    &quot;四川大学&quot;, 
    &quot;四川师范大学&quot;, 
    &quot;西南财经大学&quot;, 
    &quot;西南交通大学&quot;,
    &quot;西南石油大学&quot;, 
    &quot;中央民族大学&quot;
]

wordlist, cnt, maxlen = load_wordlist('wordlist.dic')

FMM_cut = lambda line : FMM(line, wordlist, maxlen)
BMM_cut = lambda line : BMM(line, wordlist, maxlen)

methods = [
    ('jieba', jieba.lcut),
    ('FMM', FMM_cut),
    ('BMM', BMM_cut)
]

tot_hits = {'FMM': 0, 'BMM': 0}         # 统计 FMM/BMM 分词结果正确的个数
tot_result_cnt = {'FMM': 0, 'BMM': 0}   # 统计 FMM/BMM 分词结果的个数
tot_truth_cnt = 0                       # 统计 jieba 分词结果的个数

new_words = []

for path in trainning_file_path:
    # 对某一目录下结果进行处理
    for filename, results in process_path(path, methods):
        truth = results['jieba']
        fmm = results['FMM']
        bmm = results['BMM']

        hits, len_truth, len_result, missmatches = calc_hits(truth, fmm)
        tot_hits['FMM'] += hits
        tot_result_cnt['FMM'] += len_result
        new_words += missmatches

        hits, len_truth, len_result, missmatches = calc_hits(truth, bmm)
        tot_hits['BMM'] += hits
        tot_result_cnt['BMM'] += len_result
        new_words += missmatches
        
        tot_truth_cnt += len_truth
        
        # 对同一个文档进行的 FMM 和 BMM 处理，虽然存在差异
        # 但大部分分词结果相同，故只将 FMM 分词结果存储

        write_results(filename, {'FMM': results[&quot;FMM&quot;]}, '/')

import print_helper as helper

# 打印统计信息

helper.print_stat('FMM', tot_truth_cnt, tot_result_cnt['FMM'], tot_hits['FMM'])
helper.print_stat('BMM', tot_truth_cnt, tot_result_cnt['BMM'], tot_hits['BMM'])

# 将新词添加入词典
wordlist, cnt, maxlen = add_words(wordlist, cnt, maxlen, new_words)

save_wordlist('new_wordlist.dic', wordlist)
</code></pre>
<p>使用训练后得到的词典进行结果评估：</p>
<p><a href="./test.py">test.py</a></p>
<pre><code class="language-python">import jieba
from FMM_BMM_trie import *   # 根据路径不同修改
from calc import *
from file_processing import * 

wordlist, cnt, maxlen = load_wordlist('new_wordlist.Dic')

print(&quot;------------------训练后---------------------&quot;)

FMM_cut = lambda line : FMM(line, wordlist, maxlen)
BMM_cut = lambda line : BMM(line, wordlist, maxlen)

methods = [
    ('jieba', jieba.lcut),
    ('FMM', FMM_cut),
    ('BMM', BMM_cut)
]

test_file_path = [&quot;重庆大学&quot;, &quot;西华大学&quot;]

tot_hits = {'FMM': 0, 'BMM': 0}
tot_result_cnt = {'FMM': 0, 'BMM': 0}
tot_truth_cnt = 0

for path in test_file_path:
    # 对某一目录下结果进行处理
    for filename, results in process_path(path, methods):
        truth = results['jieba']
        fmm = results['FMM']
        bmm = results['BMM']

        hits, len_truth, len_result, _ = calc_hits(truth, fmm)
        tot_hits['FMM'] += hits
        tot_result_cnt['FMM'] += len_result

        hits, len_truth, len_result, _ = calc_hits(truth, bmm)
        tot_hits['BMM'] += hits
        tot_result_cnt['BMM'] += len_result
        
        tot_truth_cnt += len_truth

import print_helper as helper

# 打印统计信息

helper.print_stat('FMM', tot_truth_cnt, tot_result_cnt['FMM'], tot_hits['FMM'])
helper.print_stat('BMM', tot_truth_cnt, tot_result_cnt['BMM'], tot_hits['BMM'])
</code></pre>
<h2 id="五实验结果"><a class="header" href="#五实验结果">五、实验结果</a></h2>
<figure>
<p><img src="./assets/FMM.png" alt="FMM Result Beforen Train" /></p>
<figcaption>图 1：FMM 分词结果评估</figcaption>
</figure>
<figure>
<p><img src="./assets/BMM.png" alt="BMM Result Beforen Train" /></p>
<figcaption>图 2：BMM 分词结果评估</figcaption>
</figure>
<figure>
<p><img src="./assets/FMM-after.png" alt="FMM Result After Train" /></p>
<figcaption>图 3：添加词典后分词结果（FMM）</figcaption>
</figure>
<h2 id="六总结"><a class="header" href="#六总结">六、总结</a></h2>
<h3 id="关于如何计算正确匹配数"><a class="header" href="#关于如何计算正确匹配数">关于如何计算正确匹配数</a></h3>
<p>简单的方法是，</p>
<pre><code class="language-python">hits += len([i for i in result if i in truth]) 
miss += [i for i in result if i not in truth]
</code></pre>
<p>使用这种方法，当一句话中出现多个相同词汇时，可能会对结果造成影响。可以根据逗号（，）等符号将语句切分为不同的小段，并对每一个小段进行处理，可以较大程度上减少相同词汇出现的概率，一定程度上保证统计的正确率。</p>
<p>本次实验采用了如 <a href="./calc.py">calc.py</a> 中 <code>calc_hits</code> 方法的实现。</p>
<h2 id="参考资料"><a class="header" href="#参考资料">参考资料</a></h2>
<ul>
<li><a href="https://blog.csdn.net/u013510838/article/details/81673016">自然语言处理 1：分词 - CSDN</a></li>
<li><a href="https://blog.csdn.net/u013510838/article/details/81738431">自然语言处理 2：jieba 分词用法及原理 - CSDN</a></li>
<li><a href="https://github.com/fxsjy/jieba">fxsjy/jieba - GitHub</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/100552669">NLP 中文分词的评估指标 - 知乎</a></li>
<li><a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural language processing - Wikipedia</a></li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../../lab/01/index.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                            <a rel="next" href="../../lab/misc/report-template.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../../lab/01/index.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                    <a rel="next" href="../../lab/misc/report-template.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="../../elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="../../book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
    </body>
</html>
